{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import xlsxwriter\n",
    "from googletrans import Translator\n",
    "\n",
    "now =time.gmtime(time.time())\n",
    "columns = [\"title\", \"korean\", \"length_of_news\", \"link\"]\n",
    "# https://github.com/ssut/py-googletrans\n",
    "google_translator = Translator(service_urls=[\n",
    "        'translate.google.cn',\n",
    "    ])\n",
    "length_limit = 1000\n",
    "\n",
    "###########################################################################################\n",
    "#eastday\n",
    "html_eastday_scroll = urlopen(\"http://news.eastday.com/gd2008/sh/index.html?t=true\")  \n",
    "\n",
    "bs_eastday_scroll = BeautifulSoup(html_eastday_scroll, \"html.parser\", from_encoding=\"cp936\") \n",
    "\n",
    "eastday_titles = []\n",
    "eastday_translated_titles = []\n",
    "eastday_links = []\n",
    "eastday_lens = []\n",
    "\n",
    "for link in bs_eastday_scroll.find(\"div\", {\"class\": \"leftsection\"}).find_all(\"a\"):\n",
    "\n",
    "    html_eastday_title = link.text.strip()\n",
    "    html_eastday_link = link.get(\"href\")\n",
    "    if html_eastday_link.count(\"http\"):\n",
    "        eastday_titles.append(html_eastday_title)\n",
    "#         print(html_eastday_title)\n",
    "        eastday_translated_titles.append(google_translator.translate(html_eastday_title, dest='ko').text)\n",
    "        eastday_links.append(html_eastday_link)\n",
    "        \n",
    "#xinminwang\n",
    "html_xinmin_scroll = urlopen(\"http://www.xinmin.cn/rollnews/index.htm\")  \n",
    "\n",
    "bs_xinmin_scroll = BeautifulSoup(html_xinmin_scroll, \"html.parser\", from_encoding=\"cp936\") \n",
    "\n",
    "xinmin_titles = []\n",
    "xinmin_translated_titles = []\n",
    "xinmin_links = []\n",
    "xinmin_lens = []\n",
    "  \n",
    "for link in bs_xinmin_scroll.find_all(\"div\", {\"class\": \"cont_full\"}):\n",
    "    html_xinmin_title = link.find(\"a\").text.strip()\n",
    "    html_xinmin_link = link.find(\"a\").get(\"href\")\n",
    "    if html_xinmin_link.count(\"http\"):\n",
    "        xinmin_titles.append(html_xinmin_title)\n",
    "        xinmin_translated_titles.append(google_translator.translate(html_xinmin_title, dest=\"ko\").text)\n",
    "        xinmin_links.append(html_xinmin_link)\n",
    "        \n",
    "#renminwang_edu\n",
    "html_renmin_edu_scroll = urlopen(\"http://edu.people.com.cn/GB/1053/index.html\")  \n",
    "\n",
    "bs_renmin_edu_scroll = BeautifulSoup(html_renmin_edu_scroll, \"html.parser\", from_encoding=\"cp936\") \n",
    "\n",
    "renmin_edu_titles = []\n",
    "renmin_edu_translated_titles = []\n",
    "renmin_edu_links = []\n",
    "renmin_edu_lens = []\n",
    "\n",
    "\n",
    "for link in bs_renmin_edu_scroll.find(\"div\", {\"class\": \"ej_list_box clear\"}).find_all(\"a\"):\n",
    "\n",
    "    html_renmin_edu_title = link.text.strip()\n",
    "    html_renmin_edu_link = link.get(\"href\")\n",
    "#     print(html_renmin_edu_title, html_renmin_edu_link)\n",
    "    if now.tm_mday < 10:\n",
    "        now_day = \"0\" + str(now.tm_mday)\n",
    "    else:\n",
    "        now_day = str(now.tm_mday)\n",
    "        \n",
    "    if html_renmin_edu_link and html_renmin_edu_link.count(str(now.tm_mon)+now_day):\n",
    "        renmin_edu_titles.append(html_renmin_edu_title)\n",
    "#         print(html_renmin_edu_title)\n",
    "        renmin_edu_translated_titles.append(google_translator.translate(html_renmin_edu_title, dest='ko').text)\n",
    "        renmin_edu_links.append('http://edu.people.com.cn/' + html_renmin_edu_link)\n",
    "    \n",
    "#online_shanghai\n",
    "\n",
    "online_sh_titles = []\n",
    "online_sh_translated_titles = []\n",
    "online_sh_links = []\n",
    "online_sh_lens = []\n",
    "\n",
    "for n in range(1,4):\n",
    "\tif n == 1:\n",
    "\t\thtml_online_sh_scroll = urlopen(\"https://hot.online.sh.cn/node/node_65634.htm\")  \n",
    "\telse:\n",
    "\t\thtml_online_sh_scroll = urlopen(\"https://hot.online.sh.cn/node/node_65634_{}.htm\".format(n))  \n",
    "\tbs_online_sh_scroll = BeautifulSoup(html_online_sh_scroll, \"html.parser\", from_encoding=\"cp936\") \n",
    "\n",
    "\n",
    "\n",
    "\tfor link in bs_online_sh_scroll.find_all(\"div\", {\"class\": \"list_thread\"}):\n",
    "\t\ttemp_link= link.find(\"a\")\n",
    "\t\thtml_online_sh_title = temp_link.text.strip()\n",
    "\t\thtml_online_sh_link = temp_link.get(\"href\")\n",
    "\n",
    "\t\tif html_online_sh_link.count(str(now.tm_mday)):\n",
    "\t\t\tonline_sh_titles.append(html_online_sh_title)\n",
    "\n",
    "\t\t\tonline_sh_translated_titles.append(google_translator.translate(html_online_sh_title, dest='ko').text)\n",
    "\t\t\tonline_sh_links.append('https://hot.online.sh.cn/' + html_online_sh_link[2:])\n",
    "            \n",
    "#sina_sh_edu\n",
    "\n",
    "sina_sh_edu_titles = []\n",
    "sina_sh_edu_translated_titles = []\n",
    "sina_sh_edu_links = []\n",
    "sina_sh_edu_lens = []\n",
    "\n",
    "class_list = [[\"div\",\"nav-content-block\"], [\"ul\",\"seo_data_list\"]]\n",
    "for n in range(1,3):\n",
    "    if n == 1:\n",
    "        html_sina_sh_edu_scroll = urlopen(\"http://sh.sina.com.cn/\")  \n",
    "    else:\n",
    "        html_sina_sh_edu_scroll = urlopen(\"http://edu.sina.com.cn/\")  \n",
    "    bs_sina_sh_edu_scroll = BeautifulSoup(html_sina_sh_edu_scroll, \"html.parser\", from_encoding=\"cp936\") \n",
    "\n",
    "#     print(bs_sina_sh_edu_scroll.find(\"ul\", {\"class\":\"seo_data_list\" }))\n",
    "    \n",
    "#     if n == 2:\n",
    "        \n",
    "    for link in bs_sina_sh_edu_scroll.find(class_list[n-1][0], {\"class\":class_list[n-1][1] }).find_all(\"a\"):\n",
    "#         print(link)\n",
    "        html_sina_sh_edu_title = link.text.strip()\n",
    "        html_sina_sh_edu_link = link.get(\"href\")\n",
    "        \n",
    "        if now.tm_mday < 10:\n",
    "            now_day = \"0\" + str(now.tm_mday)\n",
    "        else:\n",
    "            now_day = str(now.tm_mday)\n",
    "            \n",
    "        if html_sina_sh_edu_link.count(str(now.tm_mon)+\"-\"+now_day):\n",
    "            sina_sh_edu_titles.append(html_sina_sh_edu_title)\n",
    "\n",
    "            sina_sh_edu_translated_titles.append(google_translator.translate(html_sina_sh_edu_title, dest='ko').text)\n",
    "            sina_sh_edu_links.append(html_sina_sh_edu_link)\n",
    "            \n",
    "###############################################################################################################\n",
    "\n",
    "for html_eastday_title, html_eastday_link in zip(eastday_titles, eastday_links):\n",
    "    html_eastday = urlopen(html_eastday_link)\n",
    "    bs_eastday = BeautifulSoup(html_eastday, \"html.parser\", from_encoding=\"cp936\")\n",
    "    content = \"\"\n",
    "    try:\n",
    "        for con in bs_eastday.find('div', {'id' : 'zw'}).find_all('p'):\n",
    "            temp_con = con.text.strip()\n",
    "            if re.search(u'[\\u4e00-\\u9fff]', temp_con):\n",
    "                content += temp_con\n",
    "    except:\n",
    "        pass\n",
    "    eastday_lens.append(len(content))\n",
    "\n",
    "\n",
    "eastday_data = {\n",
    "    columns[0]:eastday_titles,\n",
    "    columns[1]:eastday_translated_titles,\n",
    "    columns[2]:eastday_lens,\n",
    "    columns[3]:eastday_links\n",
    "}\n",
    "\n",
    "eastday_frame = pd.DataFrame(eastday_data, columns=columns)\n",
    "eastday_frame.sort_values(columns[2], axis = 0, ascending = True, inplace = True, na_position ='first') \n",
    "\n",
    "for html_xinmin_title, html_xinmin_link in zip(xinmin_titles, xinmin_links):\n",
    "    html_xinmin = urlopen(html_xinmin_link)\n",
    "    bs_xinmin = BeautifulSoup(html_xinmin, \"html.parser\", from_encoding=\"cp936\")\n",
    "    content = \"\"\n",
    "    try:\n",
    "        for con in bs_xinmin.find('div', {'class' : 'a_content'}).find_all('p'):\n",
    "            temp_con = con.text.strip()\n",
    "            if re.search(u'[\\u4e00-\\u9fff]', temp_con):\n",
    "                content += temp_con\n",
    "    except:\n",
    "        pass\n",
    "    xinmin_lens.append(len(content))\n",
    "\n",
    "\n",
    "xinmin_data = {\n",
    "    columns[0]:xinmin_titles,\n",
    "    columns[1]:xinmin_translated_titles,\n",
    "    columns[2]:xinmin_lens,\n",
    "    columns[3]:xinmin_links\n",
    "}\n",
    "\n",
    "xinmin_frame = pd.DataFrame(xinmin_data, columns=columns)\n",
    "xinmin_frame.sort_values(columns[2], axis = 0, ascending = True, inplace = True, na_position ='first') \n",
    "\n",
    "for html_renmin_edu_title, html_renmin_edu_link in zip(renmin_edu_titles, renmin_edu_links):\n",
    "    html_renmin_edu = urlopen(html_renmin_edu_link)\n",
    "    bs_renmin_edu = BeautifulSoup(html_renmin_edu, \"html.parser\", from_encoding=\"cp936\")\n",
    "    content = \"\"\n",
    "    try:\n",
    "        for con in bs_renmin_edu.find('div', {'class' : 'fl text_con_left'}).find_all('p'):\n",
    "            temp_con = con.text.strip()\n",
    "            if re.search(u'[\\u4e00-\\u9fff]', temp_con):\n",
    "                content += temp_con\n",
    "    except:\n",
    "        pass\n",
    "    renmin_edu_lens.append(len(content))\n",
    "\n",
    "\n",
    "renmin_edu_data = {\n",
    "    columns[0]:renmin_edu_titles,\n",
    "    columns[1]:renmin_edu_translated_titles,\n",
    "    columns[2]:renmin_edu_lens,\n",
    "    columns[3]:renmin_edu_links\n",
    "}\n",
    "\n",
    "renmin_edu_frame = pd.DataFrame(renmin_edu_data, columns=columns)\n",
    "renmin_edu_frame.sort_values(columns[2], axis = 0, ascending = True, inplace = True, na_position ='first') \n",
    "\n",
    "for html_online_sh_title, html_online_sh_link in zip(online_sh_titles, online_sh_links):\n",
    "    html_online_sh = urlopen(html_online_sh_link)\n",
    "    bs_online_sh = BeautifulSoup(html_online_sh, \"html.parser\", from_encoding=\"cp936\")\n",
    "    content = \"\"\n",
    "    try:\n",
    "        for con in bs_online_sh.find('div', {'class' : 'post_text'}).find_all('p'):\n",
    "            temp_con = con.text.strip()\n",
    "            if re.search(u'[\\u4e00-\\u9fff]', temp_con):\n",
    "                content += temp_con\n",
    "    except:\n",
    "        pass\n",
    "    online_sh_lens.append(len(content))\n",
    "\n",
    "\n",
    "online_sh_data = {\n",
    "    columns[0]:online_sh_titles,\n",
    "    columns[1]:online_sh_translated_titles,\n",
    "    columns[2]:online_sh_lens,\n",
    "    columns[3]:online_sh_links\n",
    "}\n",
    "\n",
    "online_sh_frame = pd.DataFrame(online_sh_data, columns=columns)\n",
    "online_sh_frame.sort_values(columns[2], axis = 0, ascending = True, inplace = True, na_position ='first') \n",
    "\n",
    "for html_sina_sh_edu_title, html_sina_sh_edu_link in zip(sina_sh_edu_titles, sina_sh_edu_links):\n",
    "    html_sina_sh_edu = urlopen(html_sina_sh_edu_link)\n",
    "    if html_sina_sh_edu_link.count(\"edu.sina.com.cn\"):\n",
    "        key = \"article\"\n",
    "    else:\n",
    "        key = \"article-body main-body\"\n",
    "    bs_sina_sh_edu = BeautifulSoup(html_sina_sh_edu, \"html.parser\", from_encoding=\"cp936\")\n",
    "    content = \"\"\n",
    "    try:\n",
    "        for con in bs_sina_sh_edu.find('div', {'class' : key}).find_all('p'):\n",
    "            temp_con = con.text.strip()\n",
    "            if re.search(u'[\\u4e00-\\u9fff]', temp_con):\n",
    "                content += temp_con\n",
    "    except:\n",
    "        pass\n",
    "    sina_sh_edu_lens.append(len(content))\n",
    "    \n",
    "\n",
    "sina_sh_edu_data = {\n",
    "    columns[0]:sina_sh_edu_titles,\n",
    "    columns[1]:sina_sh_edu_translated_titles,\n",
    "    columns[2]:sina_sh_edu_lens,\n",
    "    columns[3]:sina_sh_edu_links\n",
    "}\n",
    "\n",
    "sina_sh_edu_frame = pd.DataFrame(sina_sh_edu_data, columns=columns)\n",
    "sina_sh_edu_frame.sort_values(columns[2], axis = 0, ascending = True, inplace = True, na_position ='first') \n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "#writer\n",
    "\n",
    "writer = pd.ExcelWriter(\"{}_{}_{}_data.xlsx\".format(now.tm_year, now.tm_mon, now.tm_mday), engine = \"xlsxwriter\")\n",
    "\n",
    "dfs = {\"eastday\":eastday_frame, \"xinmin\":xinmin_frame, \"renmin_edu\":renmin_edu_frame, \"online_sh\":online_sh_frame, \"sina_sh_edu\":sina_sh_edu_frame}\n",
    "\n",
    "for sheet_name in dfs.keys():\n",
    "    dfs[sheet_name].to_excel(writer, sheet_name= sheet_name, index=False)\n",
    "    \n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
